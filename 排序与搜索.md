排序与搜索
===

# 5 排序与搜索 #

## 5.1 目标 ##

- 了解和实现顺序搜索和二分搜索。
- 了解和实现选择排序，冒泡排序，归并排序，快速排序，插入排序和希尔排序。
- 了解搜索技术中的哈希算法。
- 了解抽象数据类型Map。
- 利用哈希实现抽象数据类型Map。

## 5.2 搜索 ##

现在开始研究搜索和排序，它们是计算中的常见问题。本节将介绍搜索，排序在稍后的章节。搜索是在元素的容器中找到某个特定元素的算法过程。通常来说，搜索会返回True或者False来表示目标项是否存在。有时也可能返回目标项所在位置。考虑到本节的目标，此处仅研究是否存在的问题。

Python提供了一个非常简便的用于判断元素是否存在于容器中，即使用in操作符。
```Python
>>> 15 in [3,5,2,4,1]
False
>>> 3 in [3,5,2,4,1]
True
>>>
```
虽然这个代码很容易写出来，但显然也需要执行某个底层程序。事实上，有许多方法实现搜索。本节关心的是这些算法是如何运行以及它们之间如何进行对比。

## 5.3 顺序搜索 ##

当元素被存入容器中，比如说列表，这些元素便有了线性或者说顺序关系。每个数据项都被存储在与其它数据项相对的位置。以Python列表来说，所谓的相对位置即是各元素的索引值（index）。由于索引值是有序的，因此对其可以进行顺序访问。这一过程便产生了第一种搜索技术，顺序搜索。

顺序搜索如图1所示。从列表的第1项开始，依次逐项移动，按照顺序即可，直到遍历尽所有元素。当遍历了所有数据后，最终发现目标项并不在该列表中。

![../_images/seqsearch.png](http://interactivepython.org/courselib/static/pythonds/_images/seqsearch.png)

该算法的Python实现如代码片段1所示。该函数接受一个列表和一个目标项作为参数并返回布尔值表示是否存在。
```Python
| 1 | def sequentialSearch(alist, item): |
| 2 |     pos = 0 |
| 3 |     found = False |
| 4 |  |
| 5 |     while pos < len(alist) and not found: |
| 6 |         if alist[pos] == item: |
| 7 |             found = True |
| 8 |         else: |
| 9 |             pos = pos+1 |
| 10 |  |
| 11 |     return found |
| 12 |  |
| 13 | testlist = [1, 2, 32, 8, 17, 19, 42, 13, 0] |
| 14 | print(sequentialSearch(testlist, 3)) |
| 15 | print(sequentialSearch(testlist, 13)) |
```
** 代码片段1:无序列表的顺序搜索 **

## 5.3.1 顺序搜索分析 ##

为了分析搜索算法，有必要确定一个基本的计算单位。回想一下，一般来说，这个基本单位就是解决问题所需要的步骤数。就搜索来说，可以采用核对次数作为基本单位。此外，这里做了一个假设：列表是无序的，即元素在列表中的位置是随机的。换句话说，在任意位置找到目标项的概率都是一样的。

若目标项并不存在于列表中，确定此事实的唯一办法是将其与每一项进行对比。如果有n项，那么顺序搜索需要进行n次核对来确认目标项确实不存在。若目标项在列表中，分析起来就不是那么直接了。实际上有3种情况。最好的情况是目标项就在列表的首项，此时仅只需一次对比。最差的情况是，直到最后一项才找到目标项，此时进行了n次对比。

平均起来，应该是在列表的中部发现目标项，也就是说，需要进行$\frac{n}{2}$次对比。读者应该还记得，随着n的增大，不管系数为多少实际上都没意义了，因此顺序搜索的时间复杂度是O(n)，如表1所示。

| **Case** | **Best Case** | **Worst Case** | **Average Case** |
| --- | --- | --- | --- |
| item is present | 1 | n | $2^n$ |
| item is not present | n | n | n |

之前假设了容器中的元素相互之间是没有位置关系的。那么假如这些元素有某种顺序的话，顺序搜索又是如何？能否在效率方面获得提升？

假定列表中的各项是以递增的关系构建的。如果目标项在列表中，在n个位置中的某一个找到该元素的概率跟之前是一样，依然要进行n次核对。然而，假如该项不存在于列表中，便可以获得一些提升。图2演示了搜索50的过程。注意，顺序对比进行到54时停止了，因为此时确定一些其它的东西：在54之后也不会有目标项存在了，因为该列表是有序的。在这种情况下，算法并不需要遍历完整个列表来确定目标项不存在，它可以立刻停止。代码片段2给出了上述的Python代码。

![../_images/seqsearch2.png](http://interactivepython.org/courselib/static/pythonds/_images/seqsearch2.png)

**代码片段2:有序列表的顺序搜索**
```Python
| 1 | def orderedSequentialSearch(alist, item): |
| 2 |     pos = 0 |
| 3 |     found = False |
| 4 |     stop = False |
| 5 |     while pos < len(alist) and not found and not stop: |
| 6 |         if alist[pos] == item: |
| 7 |             found = True |
| 8 |         else: |
| 9 |             if alist[pos] > item: |
| 10 |                 stop = True |
| 11 |             else: |
| 12 |                 pos = pos+1 |
| 13 |  |
| 14 |     return found |
| 15 |  |
| 16 | testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,] |
| 17 | print(orderedSequentialSearch(testlist, 3)) |
| 18 | print(orderedSequentialSearch(testlist, 13)) |
```
表2对这些结果进行了总结。注意，确认列表中不含目标项的最好情况是只看1项。平均来看，也需要遍历$\frac{n}{2}$项，因此其时间复杂度仍然是O(n)。总儿言之，顺序搜索仅在有序列表中不含目标项时能够有所提升。

## 5.4 二分搜索 ##

采用更加灵巧的办法来进行比较的话，可以更好地利用有序列表的优势。在顺序搜索中，当与第一项进行对比时，如果第1项不是目标项的话，便最多会有n-1项需要遍历。二分法从中间项开始进行搜索，而不是从第一项。如果该项恰好就是目标项，那么便完成了。如果不是，便可以利用列表的有序性排除一半的剩余项。如果目标项比该项大，那么便可以确定列表的较小的那一半以及当前的中间项排除了。如果该项在列表中，那么一定是在更大的那一半中。

在较大的那一半中重复以上过程。从中间项开始并且与目标项进行对比，同样，要么找到目标项，要么再将搜索的列表分割一次，从而将搜索空间再次缩小一半。该算法可以快速地找到54，如图3所示，完整代码如代码片段3所示。

![../_images/binsearch.png](http://interactivepython.org/courselib/static/pythonds/_images/binsearch.png)

**代码片段3:有序列表的二分搜索**
```Python
| 1 | def binarySearch(alist, item): |
| 2 |     first = 0 |
| 3 |     last = len(alist)-1 |
| 4 |     found = False |
| 5 |  |
| 6 |     while first<=last and not found: |
| 7 |         midpoint = (first + last)//2 |
| 8 |         if alist[midpoint] == item: |
| 9 |             found = True |
| 10 |         else: |
| 11 |             if item < alist[midpoint]: |
| 12 |                 last = midpoint-1 |
| 13 |             else: |
| 14 |                 first = midpoint+1 |
| 15 |  |
| 16 |     return found |
```
在进行分析之前，读者应当已注意到该算法是典型的**分而治之**策略。分而治之即将问题分为多个小规模的部分，以某种方式将各部分进行解决，最后重组为整个问题来获得解。对列表进行二分搜索时，首先检查的是中间项。如果目标项比中间项更小，便可以对原列表的左侧部分再进行二分搜索。反之，则对右侧进行二分搜索。不管是哪种，实质都是对二分搜索函数的递归调用，并且传入的是更小规模的列表。代码片段4给出了该递归算法。

** 代码片段4:二分搜索（递归版）**
```Python
| 1 | def binarySearch(alist, item): |
| 2 |     if len(alist) == 0: |
| 3 |         return False |
| 4 |     else: |
| 5 |         midpoint = len(alist)//2 |
| 6 |         if alist[midpoint]==item: |
| 7 |           return True |
| 8 |         else: |
| 9 |           if item<alist[midpoint]: |
| 10 |             return binarySearch(alist[:midpoint],item) |
| 11 |           else: |
| 12 |             return binarySearch(alist[midpoint+1:],item) |
| 13 |  |
| 14 | testlist = [0, 1, 2, 8, 13, 17, 19, 32, 42,] |
| 15 | print(binarySearch(testlist, 3)) |
| 16 | print(binarySearch(testlist, 13)) |
```
### 5.4.1 二分搜索的分析 ###

要对二分搜索算法进行分析，一定要谨记每次对比后都将问题规模缩小了一半。那么对整个列表进行比较时，该算法所需最多的对比次数是多少？如果从n项开始，在第1次对比后将剩下$n/2$项；在第2次对比后，将剩下$n/4$项....那么到底可以分割多少次呢？表3可以给出该答案。

| **Comparisons** | **Approximate Number of Items Left** |
| --- | --- |
| 1 | $n/2$ |
| 2 | $n/4$ |
| 3 | $n/8$ |
| ... |   |
| i | $n/4^i$ |

如果拆分次数足够高，最后就只剩下了1项，该项要么是目标项要么不是。不管是哪种情况，算法都结束了。执行到这一步所需要的对比次数i满足$\frac{n}{2^i}=1$，解得$i=logn$。最大对比次数是列表元素个数的对数函数，因此二分搜索的时间复杂度是O(logn)。

还有一个问题需要注意，在给出的递归算法中，递归调用binarySearch(alist[:midpoint],item)使用了切片操作符来生成下一次调用所需的列表左侧。在上述分析中是假定切片操作符的时间复杂度为常数即O(1)。然而在Python中，切片运算的时间复杂度实际上是O(k)。这意味着使用切片操作符的二分搜索并不会严格地符合对数时间复杂度。幸运的是，这可以通过传递列表的开始和结束索引值来解决。索引值可以通过代码3来解决，其实现就作为练习。

虽然二分搜索一般来说比顺序搜索更优，然而值得注意的是，当n比较小的时候，排序所附带的额外消耗或许是不划算的。实际上，需要考虑是否值得进行排序来获得二分搜索的优势。如果排序1次而进行多次搜索，那么排序的开销也就不那么突出了。然而，对于大列表来说，进行排序的开销可以是非常巨大的，此时进行顺序搜索有可能会是最佳选择了。

** 5.5 哈希 ##

在之前的章节中，读者应该已经注意到了，可以利用容器中元素之间相对位置的信息来优化搜索算法。比如说，如果知道列表是有序的，那么便可以通过二分搜索实现对数复杂度。在本节中，将通过建立一种新的数据结构来实现O(1)的搜索算法时间复杂度。该概念被称为**哈希**（hash）。

为此，当在容器中进行搜索时，必须掌握更多各项可能位置的信息。如果每一项都在正确的位置上，搜索过程只需要进行一次便可以找到目标项。然而，通常情况都不会这么简单。

**哈希表（hash table）**是一种容器，其中的元素以一定的方式进行存储来使得搜索操作更加方便。哈希表的每一个位置，通常被称为**槽（slot）**，可以容纳一个元素，并且以从0开始的整数对其命名。例如，第1个槽记为0，第2个槽记为1，第3个槽为2，以此类推。在初始化时，哈希表中是没有元素的，因此每个槽都为空。可以利用列表实现哈希表，其中的每个元素都被初始化为Python特殊值None。如图4所示，该哈希表长度为m=11。换言之，表中有m个槽，依次命名为0到10。

![../_images/hashtable.png](http://interactivepython.org/courselib/static/pythonds/_images/hashtable.png)

某个元素与其在哈希表对应的槽之间的映射关系被成为**哈希函数**。哈希函数会将容器中的任意元素映射到槽命名区间之间的某个整数，即0到m-1。假设有一列整数54,26,93,17,77,31。先给出第1个哈希函数，有时被称为“求余法”，简单地将该元素与哈希表大小相除，得到的余数作为哈希值（h(item)=item%11)，如表4所示。注意求余法（或者求模法)广泛地以某种形式出现在各种哈希函数中，因为其结果必须在槽命名空间内。

| **Item** | **Hash Value** |
| --- | --- |
| 54 | 10 |
| 26 | 4 |
| 93 | 5 |
| 17 | 6 |
| 77 | 0 |
| 31 | 9 |

一旦哈希值计算完成，便可以将各项插入哈希表中的指定位置，如图5所示。可以发现，11个槽中仅有6个非空。这被称为**负载系数（load factor）**，一般表示为$λ=\frac{元素个数}{哈希表长度}$，比如本例为$λ=\frac{6}{11}$。

![../_images/hashtable2.png](http://interactivepython.org/courselib/static/pythonds/_images/hashtable2.png)


当进行搜索时，简单地使用哈希函数计算出槽的名字，然后在哈希表中检查是否存在即可。该搜索操作为O(1)，因为计算哈希值并且在哈希表中对该位置进行索引所消耗的时间为常数。若所有元素都在合适的位置，那么便获得了一种时间复杂度为常数的算法。

读者可能已经看出了该技术实现的关键在于必须保证每个元素映射到哈希表中的位置是唯一的。比如说，如果项44是容器中的下1项，那么其哈希值为-，然而77的哈希值也是0，那么问题来了。根据该哈希函数，有2个甚至可能更多的元素都在同一个槽里，这种情况称之为**冲突（collision/clash）**。显然，这种冲突导致哈希算法不可行了。稍后将对此进一步讨论。

### 5.5.1 哈希函数 ###

给定一组元素，若某个哈希函数可以将其每个元素映射到唯一的槽中，那么该哈希函数便被称为**完美哈希函数（perfect hash function）**。若确定元素以及该容器是不可变的，那么就有可能构造出一个完美哈希函数（参考练习以了解更多关于完美哈希函数）。不过，若给定的元素容器是不加限制的，并没有系统化的方法来生成完美哈希函数。然而幸运的是，使用不完美哈希函数同样也可以获得不错的性能提升。

获得完美哈希函数的方法之一是增加哈希表的长度，以此来保证所有可能出现的元素产生的哈希值都被哈希表所包含。这一方法便保证了每一个元素都有唯一的槽，它可能对元素数较少时比较使用，但是当可能出现的元素数较大时便有些尴尬了。比如说，如果元素是9位的社会安全码时，该方法就需要近10亿个槽了。若只需为25个学生保存该数据，那可以说是浪费了巨大的内存了。

那么目标便确定了：生成一个容易计算的哈希函数，它可以最小化冲突数并且将元素平衡地分配在哈希表中。有很多常用的方法可以将求余法进行扩展。这里介绍其中的几种。

**折叠法（folding method）**先将元素分为相同长度的小部分（最后一小部分可能长度不一样），接着将这些小部分相加以得到最后的哈希值。比如说，如果元素是电话号码436-555-4601，可以将这些数字拆分为2位数的组合（43,65,55,46,01）。经过加法即 43+65+55+46+01 可以得到210。若假设哈希表有11个槽，则将210除以11得到余数1，将其保存，那么电话号码436-555-4601的哈希值为1。有些折叠法会进一步地将每一个小部分逆序。比如上面这个例子，做法是43+56+55+64+01=219，然后219 % 11=10。

另一种构造哈希函数的数值方法是**平方取中法（mid-square method）**。首先将各元素，然后取结果的部分位数。比如，假如元素为44，首先计算平方值为$44^2=1936$，